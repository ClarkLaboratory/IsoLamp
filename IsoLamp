#!/usr/bin/env bash

# get directory of IsoLamp script
SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

# if no parameters file is provided, exit
if [ -z ${1} ]
then
	echo "Please provide parameters file."
	echo "Usage: IsoLamp parameters.ini"
	exit 1
fi

# source parameters file
source ${1}

echo \
"
██ ███████  ██████  ██       █████  ███    ███ ██████  
██ ██      ██    ██ ██      ██   ██ ████  ████ ██   ██ 
██ ███████ ██    ██ ██      ███████ ██ ████ ██ ██████  
██      ██ ██    ██ ██      ██   ██ ██  ██  ██ ██      
██ ███████  ██████  ███████ ██   ██ ██      ██ ██  
"

# version info
echo "v1.0"

# if the $OUTPUT_NAME directory already exists, exit
if [ -d $OUTPUT_NAME ] 
then
	echo "$OUTPUT_NAME already exists"
	exit 1
fi

# make directories
mkdir $OUTPUT_NAME
mkdir $OUTPUT_NAME/temp_files

# make logs file
log_file="$OUTPUT_NAME/IsoLamp.logs"
# function to redirect output to the log file
function redirect_output() {
    # Redirect both stdout (1) and stderr (2) to the logs file
    {
        "$@"
    } >> "$log_file" 2>&1
}

# main script functions
function filter_reference_files() {
	
	echo "Running on reads in: $READS"
	echo "Indexing and filtering reference files..."

	# filter GTF by ensembl id
	grep $ENSG_ID $ANNOTATION > $OUTPUT_NAME/temp_files/filt_chr.gtf
	ANNOTATION_FILT=$OUTPUT_NAME/temp_files/filt_chr.gtf

	# get chr from GTF to filter genome
	chr=$( cat $ANNOTATION_FILT | sed -n '10p' | awk '{ print $1}' )
	
	# check file exists and is not empty
	if [ -e "$ANNOTATION_FILT" ]
	then 	
		if [ -s "$ANNOTATION_FILT" ]
		then
			:
		else
			echo "Failed to filter GTF, check ENSG_ID is in GTF and logs file"
			exit 1
		fi
	else
		echo "Failed to filter GTF, check ENSG_ID is in GTF and logs file"
		exit 1
	fi

	# filter and index genome FASTA
	samtools faidx $GENOME $chr -o $OUTPUT_NAME/temp_files/filt_chr.fa
	GENOME_FILT=$OUTPUT_NAME/temp_files/filt_chr.fa

	if [ -e "$GENOME_FILT" ]
	then 	
		if [ -s "$GENOME_FILT" ]
		then
			:
		else
			echo "Failed to filter genome by chromosome, check GTF and genome have the same chromosome naming and logs file"
			exit 1
		fi
	else
		echo "Failed to filter genome by chromosome, check GTF and genome have the same chromosome naming and logs file"
		exit 1
	fi

}

function check_for_fastq_or_fasta_files() {
	# exit if a directory contains empty fasta?

	if [ -d "$READS" ] 
	then
        # use find to search for FASTQ or FASTA files
        if find "$READS" -maxdepth 2 -type f \( -name "*.fastq"  -o -name "*.fastq.gz" -o -name "*.fasta" -o -name "*.fa" \) -print -quit | grep -q . 
		then
			# Check for empty files
        	empty_files=$(find "$READS" -type f -empty)
        	if [ -n "$empty_files" ]
			then
           		echo "WARNING: The following empty files were found within subdirectories of $READS:"
            	echo "$empty_files"
				echo "This may cause the program to fail."
        	fi
        else
            echo "No FASTQ or FASTA files found within subdirectories of $READS"
            exit 1
        fi

    else
        echo "Directory not found: $READS"
        exit 1
    fi
    
}

function concat_files() {
	
	mkdir $OUTPUT_NAME/temp_files/reads

	# run on all subdirectories in $READS
	find "$READS" -mindepth 1 -maxdepth 1 -type d | while read -r dir
	do

		# use basename to extract just the directory name
		dir_name=$(basename "$dir")

		# if BBMap works on gzipped files this may not be required, minimap2 works on gzipped files
		# gunzip zipped files
		for gzipped_file in "$READS/$dir_name"/*.gz 
		do
			if [ -f "$gzipped_file" ] 
			then
				#echo "Unzipping $gzipped_file..."
				gunzip "$gzipped_file"
			fi
		done
		
		# combine all sample read files into one file
		cat $READS/$dir_name/*.fa* > $OUTPUT_NAME/temp_files/reads/$dir_name.fa

	done

	# set path to reads
	path_to_reads=$OUTPUT_NAME/temp_files/reads
	
	# report metrics
	num_of_barcodes=$( ls -lh $OUTPUT_NAME/temp_files/reads/*.f* | wc -l )
	total_reads_input=$( cat $OUTPUT_NAME/temp_files/reads/*.f* | grep "^[>@]" | wc -l )
    
}

function downsampling_function() {
	if [ -z "$downsampling" ]
	then
    		downsampling=TRUE # set to the default value if empty
  	fi

	if [ "$downsampling" == TRUE ]
	then
		
		if [ -z "$number_reads_downsample" ]
		then
    		number_reads_downsample="8000" # set to the default value if empty
  		fi

		echo "Downsampling reads..."

		mkdir $OUTPUT_NAME/downsampled_reads

		function downsample_for_loop() { 
			for filename in $OUTPUT_NAME/temp_files/reads/*.fa
			do

				base=$(basename "$filename")
				sample_name="${base%.*}" 
				echo "$sample_name downsampling"
				
				# downsample the reads using reformat.sh from BBMap
				reformat.sh sample=$number_reads_downsample \
				in=$OUTPUT_NAME/temp_files/reads/$sample_name.fa \
				out=$OUTPUT_NAME/downsampled_reads/$sample_name.fa

			done
		}
		
		redirect_output downsample_for_loop

		# set path to downsampled reads
		path_to_reads=$OUTPUT_NAME/downsampled_reads

		total_reads_post_downsample=$(cat $OUTPUT_NAME/downsampled_reads/*.f* | grep "^[>@]" | wc -l)
	fi

}

function mapping_genome_function() {
	
	mkdir $OUTPUT_NAME/mapped_data

	# define max intron length for minimap2
	if [ -z "$max_intron_length" ] 
	then
		max_intron_length="400" # set to the default value if empty
	fi

	if [ -z "$splice_flank" ] 
	then
		splice_flank="yes" # set to the default value if empty
	fi
  
	echo "Mapping reads..."

	# loop through each sample/barcode and map to genome with minimap2
	for filename in "$path_to_reads"/*.fa
	do

		base=$(basename "$filename")
		sample_reads="${base%.*}" 
    
		function map_reads_minimap2() {
    		minimap2 -ax splice --eqx -G"${max_intron_length}"k --splice-flank="$splice_flank" $GENOME_FILT $path_to_reads/${sample_reads}.fa | samtools view -bh > $OUTPUT_NAME/mapped_data/${sample_reads}.bam
		}

		redirect_output map_reads_minimap2

		# filter for primary alignments only
		samtools view -h -F 2308 $OUTPUT_NAME/mapped_data/${sample_reads}.bam | samtools sort - > $OUTPUT_NAME/mapped_data/${sample_reads}_primary_sorted.bam

	done

	# merge all BAMs 
	samtools merge -f $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam $OUTPUT_NAME/mapped_data/*sorted.bam
	samtools index $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam

	if [ -e "$OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam.bai" ]
	then 
		:
	else
		echo "Failed to create BAM index, check logs file"
		exit 1
	fi

	# counts total reads in a BAM file for report
	number_reads_mapped=$(samtools view $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam | awk '{print $1}' | sort | uniq | wc -l)

}

function get_JWRs() {
	
	if [ "$extract_high_quality_SJs" == TRUE ]
	then
		
		if [ -z "$junction_window" ]
		then
    		junction_window=25 # set to the default value if empty
  		fi

		if [ -z "$JAQ" ]
		then
    		JAQ=0.8 # set to the default value if empty
  		fi
		
		python3 $SCRIPT_DIR/scripts/NanoSplicer_JWR_checker.py --window $junction_window $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_JAQ.csv
		Rscript $SCRIPT_DIR/scripts/read_list_high_JAQ.R -i $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_JAQ.csv -j $JAQ -o $OUTPUT_NAME
		samtools view -N $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_reads_above_JAQ_minimum.txt -o $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_filtered_high_JAQ_reads.bam $OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam

		number_reads_SJ=$(cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_reads_above_JAQ_minimum.txt | wc -l)

		bam_for_bambu=$OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_filtered_high_JAQ_reads.bam

	else
		
		bam_for_bambu=$OUTPUT_NAME/mapped_data/${OUTPUT_NAME}_primary_merged.bam

	fi

}

function run_bambu_function() {
	echo "Identifying novel isoforms with Bambu..."
	mkdir $OUTPUT_NAME/bambu

	if [ -z "$bambu_ndr" ] 
  	then
    	bambu_ndr=1 # set to the default value
  	fi

	if [ -z "$bambu_min_gene_fraction" ] 
  	then
    	bambu_min_gene_fraction=0.001 # set to the default value
  	fi

	# run bambu Rscript 
	redirect_output Rscript $SCRIPT_DIR/scripts/bambu_tx_discovery.R -b $bam_for_bambu \
		-f $GENOME_FILT \
		-t $ANNOTATION_FILT \
		-n $bambu_ndr \
		-g $bambu_min_gene_fraction \
		-o $OUTPUT_NAME/bambu

	if [ -e "$OUTPUT_NAME/bambu/extended_annotations.gtf" ]
	then
		if [ -s "$OUTPUT_NAME/bambu/extended_annotations.gtf" ]
		then
			:
		else
			echo "Failed to create Bambu annotations, check logs file"
			exit 1
		fi
	else
		echo "Failed to create Bambu annotations, check logs file"
		exit 1
	fi

}

function read_count_function_first_pass() {
	if [ -z "$read_count_minimum" ]
	then
    	read_count_minimum="5" # set to the default value if empty
  	fi
	
	# filter for bambu isoforms with read count > threshold 
	cat "$OUTPUT_NAME/bambu/counts_transcript.txt" | awk -v min_count="$read_count_minimum" '{ if ($3 > min_count ) print $1 }' | tail -n +2 > "$OUTPUT_NAME/temp_files/isoforms_read_count_min_first_pass.txt"

	# subset bambu GTF for the isoforms that passed threshold
	cat $OUTPUT_NAME/bambu/extended_annotations.gtf | grep -wf $OUTPUT_NAME/temp_files/isoforms_read_count_min_first_pass.txt > $OUTPUT_NAME/bambu/extended_annotations_first_pass.gtf
	
	# replace some Bambu naming conventions
	cat $OUTPUT_NAME/bambu/extended_annotations_first_pass.gtf | sed 's/tx./tx/g' | sed 's/BambuTx/tx/g' > $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf
	cat $OUTPUT_NAME/temp_files/isoforms_read_count_min_first_pass.txt | sed 's/tx./tx/g' | sed 's/BambuTx/tx/g' | awk '{ print $1"\t"$3}' > $OUTPUT_NAME/temp_files/updated_transcriptome_first_pass.txt

	# check file exists and is not empty
	if [ -e "$OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf" ]
	then 	
		if [ -s "$OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf" ]
		then
			:
		else
			echo "Read count threshold first pass failed, check logs file"
			exit 1
		fi
	else
		echo "Read count threshold first pass failed, check logs file"
		exit 1
	fi

}

function primer_site_function() {
	
	if [ -z "$primer_site_based_filter" ]
	then
    		primer_site_based_filter=FALSE # set to the default value if empty
  	fi

	if [ "$primer_site_based_filter" == TRUE ]
	then

		echo "Filtering based on primer BED files..."
		
		# intersect forward and reverse primers with GTF
		cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf | awk '{ if ($3 == "exon") print }' | bedtools intersect -wa -u -F 0.8 -a - -b $forward_primers | grep -o 'transcript_id "[^"]*' | cut -d' ' -f2 | sed 's/"//g' > $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_forward_primer_exons.txt
		cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf | awk '{ if ($3 == "exon") print }' | bedtools intersect -wa -u -F 0.8 -a - -b $reverse_primers | grep -o 'transcript_id "[^"]*' | cut -d' ' -f2 | sed 's/"//g' > $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_reverse_primer_exons.txt
		
		# combine isoforms found in both forward and reverse primers
		comm -12 <(sort $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_forward_primer_exons.txt) <(sort $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_reverse_primer_exons.txt) > $OUTPUT_NAME/temp_files/updated_transcriptome.txt
		
		# subset GTF that passed counts filtering with new list of isoforms that match primers
		cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf | grep -wf $OUTPUT_NAME/temp_files/updated_transcriptome.txt > $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_primer.gtf

		if [ -e "$OUTPUT_NAME/temp_files/updated_transcriptome.txt" ]
		then 	
			if [ -s "$OUTPUT_NAME/temp_files/updated_transcriptome.txt" ]
			then
				:
			else
				echo "Failed to filter based on primers, check logs file"
				exit 1
			fi
		else
			echo "Failed to filter based on primers, check logs file"
			exit 1
		fi

		# sum transcript counts remaining after primer filtering
		total_kept_counts=$(cat "$OUTPUT_NAME/bambu/counts_transcript.txt" | grep -wf "$OUTPUT_NAME/temp_files/updated_transcriptome.txt" | awk '{total=total+$3} END{printf "%.0f", total}')
		# sum transcript counts from Bambu
		total_bambu_counts=$(cat "$OUTPUT_NAME/bambu/counts_transcript.txt" | awk '{total=total+$3} END{printf "%.0f", total}')
		
		# calculate 90% of the total transcript counts
		primer_threshold=$(printf "%.0f" "$(echo "$total_bambu_counts * 0.9" | bc)")

		# check that at least 90% of the counts are remaining after primer filtering
		if [ "$((total_kept_counts))" -lt "$((primer_threshold))" ] 
		then
			echo "WARNING: primer filtering removed isoforms with >10% of counts assigned by Bambu"
		fi

	elif [ "$primer_site_based_filter" == FALSE ]
	then
		# use isoforms that passed read count filtering 
		cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_first_pass.gtf > $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_primer.gtf
		cat $OUTPUT_NAME/temp_files/updated_transcriptome_first_pass.txt > $OUTPUT_NAME/temp_files/updated_transcriptome.txt
	fi
}

function create_metatranscriptome() {
	echo "Mapping to updated transcriptome with novel isoforms..."
	mkdir $OUTPUT_NAME/updated_transcriptome

	# create an updated transcriptome fasta with gffread using the bambu isoforms
	redirect_output gffread -w $OUTPUT_NAME/updated_transcriptome/updated_transcriptome.fa -g $GENOME_FILT $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_primer.gtf
	
	if [ -e "$OUTPUT_NAME/updated_transcriptome/updated_transcriptome.fa" ]
  	then 
		:
 	else
		echo "Failed to create updated transcriptome with gffread, check logs file"
		exit 1
  	fi

	# create a salmon index of the updated transcriptome
	redirect_output salmon index -t $OUTPUT_NAME/updated_transcriptome/updated_transcriptome.fa -i $OUTPUT_NAME/updated_transcriptome -k 31
	
	if [ -e "$OUTPUT_NAME/updated_transcriptome/versionInfo.json" ]
  	then 
		:
 	else
		echo "Failed to index with salmon, check logs file"
		exit 1
  	fi
}

function remapping_function() {
	
	mkdir $OUTPUT_NAME/updated_transcriptome/salmon_quants

	# function to loop through reads from each sample/barcode and quantify with salmon
	running_salmon() {
		for filename in $path_to_reads/*.fa
		do

			base=$(basename $filename)
			sample_reads="${base%.*}"
			
			salmon quant --quiet -i $OUTPUT_NAME/updated_transcriptome -l A -r $path_to_reads/${sample_reads}.fa -o $OUTPUT_NAME/updated_transcriptome/salmon_quants/${sample_reads}

		done
	}

	redirect_output running_salmon
		
	if [ -d "$OUTPUT_NAME/updated_transcriptome/salmon_quants" ]
  	then
		if [ "$(ls -A $OUTPUT_NAME/updated_transcriptome/salmon_quants)" ] 
		then
     		:
		else
    		echo "Failed to quantify with salmon, check logs file"
			exit 1
		fi
 	else
		echo "Failed to quantify with salmon, check logs file"
		exit 1
  	fi

}

function combine_quants_function() {
	if [ -z "$read_count_minimum" ]
	then
    	read_count_minimum="5" # set to the default value if empty
  	fi

	if [ -z "$samples_minimum" ]
	then
		samples_minimum=$(echo "scale=0; $num_of_barcodes/2" | bc -l)
  	fi
	
	echo "Generating isoform counts..."

	# run Rscript to combine quant.sf files produced by salmon to produce isoform counts
	Rscript $SCRIPT_DIR/scripts/combine_salmon_quants.R -e $ENSG_ID -m $read_count_minimum -s $samples_minimum -o $OUTPUT_NAME

	# calculate number of reads in the isoform counts for report
	reads_remaining_final=$(cat $OUTPUT_NAME/temp_files/remaining_read_sum.txt)

}

function read_count_function_second_pass() {

	# create list in text file of isoforms that passed threshold
	# command uses _ and , as sep, prints first column of tx names, removes the word Bambu in tx names, and removes the column header
	cat $OUTPUT_NAME/${OUTPUT_NAME}_counts.csv | awk -F '[_,]' '{print $1}' | sed 's/Bambu//g' | tail -n +2 > $OUTPUT_NAME/temp_files/isoforms_read_count_min_second_pass.txt
	
	# filter GTF based on isoforms 
	cat $OUTPUT_NAME/temp_files/${OUTPUT_NAME}_isoforms_primer.gtf | grep -wif $OUTPUT_NAME/temp_files/isoforms_read_count_min_second_pass.txt > $OUTPUT_NAME/${OUTPUT_NAME}_isoforms.gtf

	# report metrics
	filtered_transcripts_known=$( cat $OUTPUT_NAME/temp_files/isoforms_read_count_min_second_pass.txt | grep -vi tx | wc -l )
	filtered_transcripts_novel=$( cat $OUTPUT_NAME/temp_files/isoforms_read_count_min_second_pass.txt | grep -i tx | wc -l )

	if [ -e "$OUTPUT_NAME/${OUTPUT_NAME}_isoforms.gtf" ]
	then 	
		if [ -s "$OUTPUT_NAME/${OUTPUT_NAME}_isoforms.gtf" ]
		then
			:
		else
			echo "Read count threshold second pass failed, check logs file"
			exit 1
		fi
	else
		echo "Read count threshold second pass failed, check logs file"
		exit 1
	fi

}

function gffcomp_function() {
	mkdir $OUTPUT_NAME/annotated_isoforms

	# create file of bambu tx classes for remaining isoforms
	{ head -n 1 $OUTPUT_NAME/bambu/bambu_tx_classes.txt && grep -wif $OUTPUT_NAME/temp_files/isoforms_read_count_min_second_pass.txt $OUTPUT_NAME/bambu/bambu_tx_classes.txt; } > $OUTPUT_NAME/annotated_isoforms/${OUTPUT_NAME}_bambu_isoform_classes.txt
	
	# run gffcompare on the new isoforms and original reference GTF
	redirect_output gffcompare -r $ANNOTATION_FILT -o $OUTPUT_NAME/annotated_isoforms/gffcomp $OUTPUT_NAME/${OUTPUT_NAME}_isoforms.gtf
	
	# put gffcompare outputs in directory
	mv $OUTPUT_NAME/gffcomp.* $OUTPUT_NAME/annotated_isoforms/

}

function sqanti_function() {
 	# source python paths for cDNA Cupcake to run with SQANTI
  	export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/sequence/:$PYTHONPATH"
  	export PYTHONPATH="$SCRIPT_DIR/scripts/cDNA_Cupcake/:$PYTHONPATH"
  
		
	python $SCRIPT_DIR/scripts/SQANTI3/sqanti3_qc.py \
		$OUTPUT_NAME/${OUTPUT_NAME}_isoforms.gtf \
		$ANNOTATION_FILT $GENOME_FILT \
		-d $OUTPUT_NAME/sqanti -o $OUTPUT_NAME/annotated_isoforms --report skip
		#--CAGE_peak $REF_HG38/refTSS_v3.3_human_coordinate.hg38.bed \
		#--polyA_peak $REF_HG38/atlas.clusters.2.0.GRCh38.96.bed --polyA_motif_list $REF_HG38/human.polyA.list.txt

}

function plot_PCA() {

	if [ -z "$grouping_data" ] 
	then
		grouping_data=NULL # set to the default value if empty
	fi

	redirect_output Rscript $SCRIPT_DIR/scripts/plot_PCA.R -i $OUTPUT_NAME/$OUTPUT_NAME"_counts.csv" -o "$OUTPUT_NAME/$OUTPUT_NAME" -g $grouping_data

}

function plot_accuarcy () {
	
	redirect_output Rscript $SCRIPT_DIR/scripts/accuracy.R $OUTPUT_NAME/mapped_data/$OUTPUT_NAME"_primary_merged.bam" "$OUTPUT_NAME/$OUTPUT_NAME"

}

function compare_proportions_test() {
	# only run if grouping is provided
	if [ -z "$grouping_data" ] 
	then
		:
	else
		echo "Comparing isoform proportions between groups..."
		redirect_output Rscript $SCRIPT_DIR/scripts/prop_t_test.R -i $OUTPUT_NAME/$OUTPUT_NAME"_proportions.csv" -o $OUTPUT_NAME -g $grouping_data
	fi

}

function generate_report_function() {
cat << EOT >> $OUTPUT_NAME/${OUTPUT_NAME}_report.txt
`date`

Filters applied:
	Downsampling: $downsampling
	Downsampled to number of reads: $number_reads_downsample
	Primer site filter: $primer_site_based_filter
	Extract high quality splice junctions: $extract_high_quality_SJs
	Read count minimum: $read_count_minimum
	Samples required to meet read count minimum: $samples_minimum
	Bambu novel discovery rate (NDR): $bambu_ndr
	Bambu minimum read fraction by gene: $bambu_min_gene_fraction

Number of input samples/barcodes: $num_of_barcodes
Total number of reads in samples/barcodes: $total_reads_input

Total number of reads in samples/barcodes post-downsampling: $total_reads_post_downsample
Number of reads mapped to genome: $number_reads_mapped
Number of reads with high quality splice junctions: $number_reads_SJ

Known isoforms identified: $filtered_transcripts_known
Novel isoforms identified: $filtered_transcripts_novel

Number of reads mapped to known/novel isoforms: $reads_remaining_final

EOT
}



########## 0. Counting the number of reads and downsampling ##########

# filter input references
filter_reference_files

# check filetypes
check_for_fastq_or_fasta_files
concat_files

# downsampling
downsampling_function


########## 1. Aligning sample fasta files to reference genome ##########

# run minimap2
mapping_genome_function

########## 2.a. Correcting and collapsing transcripts with bambu ##########

# run JWR jecker python script
get_JWRs

# run bambu in R
run_bambu_function


########## 2.b. Filtering bambu transcripts and creating a transcriptome ##########

# read count filter 
read_count_function_first_pass

# primer site filter
primer_site_function

# metatranscriptome with salmon
create_metatranscriptome


########## 2.c. Re-aligning and quantifying filtered bambu transcripts  ##########

# remap to salmon metatranscriptome
remapping_function


########## 2.d. Generating count matrix   ##########

# Rscript to combine quant.sf files and filter by read min counts
combine_quants_function

# some zero count isoforms result after the secound round of quants with salmon
read_count_function_second_pass

###### Generate plots
echo "Generating PCA plot..."
plot_PCA

echo "Generating accuarcy plot..."
plot_accuarcy 

# proportion test between groups
compare_proportions_test

########## 3. Annotating transcripts ##########
echo "Annotating isoforms..."
# run with gffcompare
gffcomp_function

# run with SQANTI
#sqanti_function


########## 4. Report ##########

# make report txt file
echo "Generating report..."
generate_report_function

# remove temp files
#rm -rf $OUTPUT_NAME/temp_files

########## Finished ##########
echo "Complete"


